# REST API Performance Benchmarking Suite

## ğŸ“‹ Project Overview
This project is a comprehensive benchmarking suite designed to compare the performance of three different Java REST API implementations:
1. **Variant A**: JAX-RS (Jersey) implementation
2. **Variant C**: Spring MVC with @RestController
3. **Variant D**: Spring Data REST

The benchmark evaluates various performance metrics including response times, throughput, and resource utilization under different load scenarios.

## ğŸ—ï¸ Project Structure
```
benchmark-main/
â”œâ”€â”€ database/           # Database schema and data initialization
â”œâ”€â”€ jmeter/             # JMeter test plans and data
â”‚   â”œâ”€â”€ scripts/        # JMeter test scenarios
â”‚   â””â”€â”€ results/        # Test execution results
â”œâ”€â”€ monitoring/         # Monitoring tools configuration
â”‚   â”œâ”€â”€ grafana/        # Grafana dashboards and provisioning
â”‚   â””â”€â”€ prometheus/     # Prometheus configuration
â”œâ”€â”€ variant-a-jaxrs/    # JAX-RS implementation
â”œâ”€â”€ variant-c-springmvc # Spring MVC implementation
â””â”€â”€ variant-d-springdata # Spring Data REST implementation
```

## ğŸ› ï¸ Technology Stack

### Backend Implementations
1. **Variant A (JAX-RS)**
   - Java 17
   - Jersey (JAX-RS 3.1.0)
   - Hibernate 6.0
   - Maven

2. **Variant C (Spring MVC)**
   - Java 17
   - Spring Boot 3.0.0
   - Spring Data JPA
   - Hibernate 6.0
   - Maven

3. **Variant D (Spring Data REST)**
   - Java 17
   - Spring Boot 3.0.0
   - Spring Data REST
   - Hibernate 6.0
   - Maven

### Database
- **PostgreSQL 14**
  - Tables: category, item
  - ~2,000 categories
  - ~100,000 items

### Testing & Monitoring
- **JMeter 5.6.2** - Load testing
- **InfluxDB 2.7** - Time-series database for metrics
- **Grafana 10.2.0** - Visualization and dashboards
- **Prometheus 2.47.0** - Metrics collection

## ğŸš€ Getting Started

### Prerequisites
- Docker Desktop for Windows
- At least 8GB free RAM
- At least 2 CPU cores
- Java 17 JDK
- Maven 3.8+

### Quick Start
1. **Start the monitoring stack**:
   ```powershell
   docker-compose up -d influxdb grafana prometheus
   ```

2. **Build the project**:
   ```powershell
   .\setup-and-build.ps1
   ```

3. **Run a variant** (A, C, or D):
   ```powershell
   .\RUN_VARIANT.ps1 A  # For Variant A (JAX-RS)
   ```

4. **Run a benchmark**:
   ```powershell
   .\run_benchmark.ps1 A read_heavy 50 60 600
   ```

## ğŸ“Š Test Scenarios

### 1. READ-heavy Workload
- **Objective**: Test read performance with high concurrency
- **Operations**:
  - 50% GET /items
  - 20% GET /items?categoryId=X
  - 20% GET /categories/X/items
  - 10% GET /categories

### 2. JOIN-filter Workload
- **Objective**: Test complex queries with joins
- **Operations**:
  - 70% GET /items?categoryId=X
  - 30% GET /items/X

### 3. MIXED Workload
- **Objective**: Test mixed read/write operations
- **Operations**:
  - 40% GET /items
  - 20% POST /items
  - 10% PUT /items/X
  - 10% DELETE /items/X
  - 10% POST /categories
  - 10% PUT /categories/X

### 4. HEAVY-body Workload
- **Objective**: Test with large payloads
- **Operations**:
  - 50% POST /items (5KB payload)
  - 50% PUT /items/X (5KB payload)

## ğŸ“ˆ Performance Metrics
The benchmark collects the following metrics:
- **Throughput**: Requests per second (RPS)
- **Response Times**: p50, p95, p99 percentiles
- **Error Rate**: Percentage of failed requests
- **Resource Usage**:
  - CPU utilization
  - Memory consumption
  - Garbage collection metrics
  - Database connection pool stats

## ğŸ“Š Monitoring Setup
1. **Grafana**: http://localhost:3000 (admin/admin)
   - Pre-configured dashboards for:
     - Application metrics
     - JVM metrics
     - Database performance

2. **Prometheus**: http://localhost:9090
   - Raw metrics collection
   - Alert rules

3. **InfluxDB**: http://localhost:8086 (admin/admin123)
   - Time-series data storage
   - Query interface at http://localhost:8086

## ğŸ“ Test Execution
1. **Single Test**:
   ```powershell
   .\run_benchmark.ps1 A read_heavy 50 60 600
   # Parameters: variant scenario threads rampup duration
   ```

2. **Full Test Suite**:
   ```powershell
   .\run_full_benchmark.ps1
   ```

## ğŸ“‚ Results
Test results are stored in the `jmeter/results` directory with the following structure:
```
results/
â”œâ”€â”€ [variant]_[scenario]_[timestamp]/
â”‚   â”œâ”€â”€ result.jtl        # Raw JMeter results
â”‚   â”œâ”€â”€ jmeter.log        # JMeter execution log
â”‚   â””â”€â”€ report/           # HTML report
â”‚       â”œâ”€â”€ index.html    # Dashboard
â”‚       â””â”€â”€ statistics.json
```

## ğŸ§ª Test Data
The database is pre-populated with:
- 2,000 categories
- 100,000 items (~50 items per category)

## ğŸ“š Documentation
- [BENCHMARK_GUIDE.md](BENCHMARK_GUIDE.md) - Detailed usage instructions
- `database/` - Database schema and data loading scripts
- `monitoring/` - Monitoring setup and configuration

## ğŸ¤ Contributing
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a new Pull Request

## ğŸ“„ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact
For questions or feedback, please open an issue in the repository.
